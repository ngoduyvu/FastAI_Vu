{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying different Algorithm for Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/paperspace/fastai/courses/dl1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/datamining/train.csv')\n",
    "df_test = pd.read_csv('./data/datamining/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>airline</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue great flight! Great view! :-) http://...</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@united they're not, actually. gate agent was ...</td>\n",
       "      <td>United</td>\n",
       "      <td>chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@AmericanAir No worries they called back 4 hrs...</td>\n",
       "      <td>American</td>\n",
       "      <td>Dallas, Texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>@united thank you. There was one here a few mo...</td>\n",
       "      <td>United</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>America/New_York</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@united Brothers luggage was lost on Copa Airl...</td>\n",
       "      <td>United</td>\n",
       "      <td>Kearney, Nebraska</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text   airline  \\\n",
       "0   0  @JetBlue great flight! Great view! :-) http://...     Delta   \n",
       "1   1  @united they're not, actually. gate agent was ...    United   \n",
       "2   2  @AmericanAir No worries they called back 4 hrs...  American   \n",
       "3   3  @united thank you. There was one here a few mo...    United   \n",
       "4   4  @united Brothers luggage was lost on Copa Airl...    United   \n",
       "\n",
       "      tweet_location               user_timezone sentiment  \n",
       "0                NaN                         NaN  positive  \n",
       "1            chicago                         NaN  negative  \n",
       "2      Dallas, Texas                         NaN  negative  \n",
       "3       New York, NY            America/New_York  positive  \n",
       "4  Kearney, Nebraska  Central Time (US & Canada)  negative  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform([r for r in df_train['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_features, \n",
    "                 df_train['sentiment'].values,        \n",
    "                 test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistis Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation: https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification rate: 0.9167468719923003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "print(\"Logistic Regression classification rate:\", LR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.92307692 0.91937425 0.90373045 0.92418773 0.90854392 0.90734055\n",
      " 0.90493381 0.90854392 0.92409639 0.91325301]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LR, X_train, y_train, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1587   57]\n",
      " [ 116  318]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.93      0.97      0.95      1644\n",
      "   positive       0.85      0.73      0.79       434\n",
      "\n",
      "avg / total       0.91      0.92      0.91      2078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = LR.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification rate: 0.9013474494706448\n"
     ]
    }
   ],
   "source": [
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "print(\"Naive Bayes classification rate:\", NB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.87860577 0.89651023 0.86883273 0.8856799  0.89169675 0.88929001\n",
      " 0.87725632 0.88808664 0.9        0.90120482]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(NB, X_train, y_train, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1576   68]\n",
      " [ 137  297]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.92      0.96      0.94      1644\n",
      "   positive       0.81      0.68      0.74       434\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = NB.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree classification rate: 0.8604427333974976\n"
     ]
    }
   ],
   "source": [
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "print(\"Decision Tree classification rate:\", DT.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.86778846 0.86642599 0.8423586  0.84356197 0.84717208 0.82912154\n",
      " 0.86281588 0.84115523 0.86506024 0.84457831]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(DT, X_train, y_train, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1490  154]\n",
      " [ 136  298]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.92      0.91      0.91      1644\n",
      "   positive       0.66      0.69      0.67       434\n",
      "\n",
      "avg / total       0.86      0.86      0.86      2078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = DT.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network classification rate: 0.8604427333974976\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20,20,20),max_iter=500)\n",
    "mlp.fit(X_train,y_train)\n",
    "print(\"Neural Network classification rate:\", DT.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1559   85]\n",
      " [ 123  311]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.93      0.95      0.94      1644\n",
      "   positive       0.79      0.72      0.75       434\n",
      "\n",
      "avg / total       0.90      0.90      0.90      2078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Bigger data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/datamining/Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.rename(columns={'airline_sentiment':'sentiment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform([r for r in df_train['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_features, \n",
    "                 df_train['sentiment'].values,        \n",
    "                 test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classification rate: 0.7756147540983607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "print(\"Logistic Regression classification rate:\", LR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.78327645 0.76450512 0.79863481 0.79010239 0.77796755 0.78650726\n",
      " 0.78992314 0.78479932 0.78736123 0.80325064]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LR, X_train, y_train, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1610  136   48]\n",
      " [ 245  337   58]\n",
      " [ 102   68  324]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.90      0.86      1794\n",
      "    neutral       0.62      0.53      0.57       640\n",
      "   positive       0.75      0.66      0.70       494\n",
      "\n",
      "avg / total       0.77      0.78      0.77      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "predictions = LR.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classification rate: 0.7592213114754098\n"
     ]
    }
   ],
   "source": [
    "# Bayesian\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB = MultinomialNB()\n",
    "NB.fit(X_train, y_train)\n",
    "print(\"Naive Bayes classification rate:\", NB.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.74488055 0.75426621 0.75426621 0.75426621 0.76345004 0.74978651\n",
      " 0.72758326 0.72843723 0.74807857 0.77331052]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(NB, X_train, y_train, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1677   79   38]\n",
      " [ 328  264   48]\n",
      " [ 157   55  282]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.78      0.93      0.85      1794\n",
      "    neutral       0.66      0.41      0.51       640\n",
      "   positive       0.77      0.57      0.65       494\n",
      "\n",
      "avg / total       0.75      0.76      0.74      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = NB.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree classification rate: 0.6796448087431693\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT.fit(X_train, y_train)\n",
    "print(\"Decision Tree classification rate:\", DT.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated scores: [0.6612628  0.69027304 0.65955631 0.66211604 0.69000854 0.69086251\n",
      " 0.66268147 0.67976089 0.68488471 0.679213  ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(DT, X_train, y_train, cv=10)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1389  295  110]\n",
      " [ 257  319   64]\n",
      " [ 121   91  282]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.79      0.77      0.78      1794\n",
      "    neutral       0.45      0.50      0.47       640\n",
      "   positive       0.62      0.57      0.59       494\n",
      "\n",
      "avg / total       0.68      0.68      0.68      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = DT.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network classification rate: 0.6796448087431693\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,20,20),max_iter=500)\n",
    "mlp.fit(X_train,y_train)\n",
    "print(\"Neural Network classification rate:\", DT.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1476  231   87]\n",
      " [ 215  353   72]\n",
      " [  97   94  303]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.82      0.82      1794\n",
      "    neutral       0.52      0.55      0.54       640\n",
      "   positive       0.66      0.61      0.63       494\n",
      "\n",
      "avg / total       0.73      0.73      0.73      2928\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
